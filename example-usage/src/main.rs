use anyhow::Result;
use std::{fs::File, io::Read};

use core::neuralnetwork::{
    errorrate::{ErrorRateData, ErrorRateEntry},
    neuralnetwork::NeuralNetwork,
    training::{TrainingData, TrainingEntry},
};

const TRAINING_LABELS: &str = "train-labels.idx1-ubyte";
const TRAINING_IMAGES: &str = "train-images.idx3-ubyte";
const TEST_LABELS: &str = "t10k-labels.idx1-ubyte";
const TEST_IMAGES: &str = "t10k-images.idx3-ubyte";

#[derive(Debug)]
struct Image {
    label: Vec<f64>,
    datapoints: Vec<f64>,
}

fn main() -> Result<()> {
    // Querying and training becomes slower the more hidden neurons and hidden layers the network has
    let mut nn = NeuralNetwork::new_with_random_values(784, 100, 10, 1);
    let testing_data = get_mnist_training_labels_and_images(TEST_LABELS, TEST_IMAGES)
        .into_iter()
        .map(|image| ErrorRateEntry {
            input: image.datapoints,
            expected_output: image.label,
        })
        .collect::<Vec<ErrorRateEntry>>();
    let training_data = get_mnist_training_labels_and_images(TRAINING_LABELS, TRAINING_IMAGES)
        .into_iter()
        .map(|image| TrainingEntry {
            input: image.datapoints,
            expected_output: image.label,
        })
        .collect::<Vec<TrainingEntry>>();
    let error_rate_before_training = nn.error_rate_of_network(&ErrorRateData(&testing_data))?;
    nn = nn.train(&TrainingData(training_data), 1, 0.1)?;
    let error_rate_after_training = nn.error_rate_of_network(&ErrorRateData(&testing_data))?;
    println!("error_rate_before_training: {}", error_rate_before_training);
    println!("error_rate_after_training: {}", error_rate_after_training);
    Ok(())
}

// Returns a vector of Images. The image has a label which is the number which is in datapoints.
// An example of a number 7 is:
// Image { label: [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 1.0, 0.01, 0.01],
// datapoints: [
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.3361176470588235, 0.7282352941176471,
// 0.6272941176470588, 0.5962352941176471, 0.24294117647058824, 0.14976470588235294,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.8718823529411764,
// 0.9961176470588236, 0.9961176470588236, 0.9961176470588236, 0.9961176470588236,
// 0.9456470588235294, 0.7787058823529412, 0.7787058823529412, 0.7787058823529412,
// 0.7787058823529412, 0.7787058823529412, 0.7787058823529412, 0.7787058823529412,
// 0.7787058823529412, 0.6699999999999999, 0.21188235294117647, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.2701176470588236,
// 0.4525882352941177, 0.28952941176470587, 0.4525882352941177, 0.6428235294117647,
// 0.8912941176470588, 0.9961176470588236, 0.8835294117647059, 0.9961176470588236,
// 0.9961176470588236, 0.9961176470588236, 0.9805882352941176, 0.8990588235294118,
// 0.9961176470588236, 0.9961176470588236, 0.5535294117647059, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.076, 0.26623529411764707, 0.06435294117647058, 0.2701176470588236,
// 0.2701176470588236, 0.2701176470588236, 0.2390588235294118, 0.09152941176470587,
// 0.9262352941176472, 0.9961176470588236, 0.42152941176470593, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.3322352941176471, 0.9922352941176471,
// 0.8214117647058823, 0.07988235294117646, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.09541176470588235, 0.9145882352941176, 1.0, 0.3322352941176471,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.5108235294117647,
// 0.9961176470588236, 0.934, 0.18082352941176472, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.2390588235294118, 0.9767058823529412, 0.9961176470588236,
// 0.25070588235294117, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.5263529411764706, 0.9961176470588236, 0.736, 0.029411764705882353, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.044941176470588234, 0.8058823529411765,
// 0.9728235294117646, 0.2351764705882353, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.49917647058823533, 0.9961176470588236, 0.7165882352941176, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.3011764705882353, 0.9844705882352941,
// 0.941764705882353, 0.23129411764705884, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.08376470588235294, 0.868, 0.9961176470588236, 0.6544705882352941, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.02164705882352941, 0.7981176470588235,
// 0.9961176470588236, 0.860235294117647, 0.1458823529411765, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.1575294117647059, 0.9961176470588236, 0.9961176470588236, 0.3089411764705882,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1303529411764706, 0.8796470588235294,
// 0.9961176470588236, 0.45647058823529413, 0.01388235294117647, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.5263529411764706, 0.9961176470588236, 0.9961176470588236, 0.21188235294117647,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.24682352941176472, 0.9495294117647058,
// 0.9961176470588236, 0.9961176470588236, 0.21188235294117647, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.4797647058823529, 0.9961176470588236, 0.9961176470588236, 0.860235294117647,
// 0.16529411764705884, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.4797647058823529,
// 0.9961176470588236, 0.8136470588235294, 0.07988235294117646, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,
// 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01] }
fn get_mnist_training_labels_and_images(
    label_file_name: &str,
    image_file_name: &str,
) -> Vec<Image> {
    let mut labels = File::open(format!(
        "{}/mnist-dataset/{}",
        env!("CARGO_MANIFEST_DIR").replace("/example-usage", ""),
        label_file_name
    ))
    .unwrap();
    let mut images = File::open(format!(
        "{}/mnist-dataset/{}",
        env!("CARGO_MANIFEST_DIR").replace("/example-usage", ""),
        image_file_name
    ))
    .unwrap();
    let mut buffer_1 = Vec::new();
    let mut buffer_2 = Vec::new();
    labels.read_to_end(&mut buffer_1).unwrap();
    images.read_to_end(&mut buffer_2).unwrap();
    //first range is meta data, check README.md inside the mnist-dataset folder
    buffer_1.drain(0..8);
    //first range is meta data, check README.md inside the mnist-dataset folder
    buffer_2.drain(0..16);
    buffer_2
        .chunks(784)
        .zip(buffer_1)
        .map(|(image, label)| {
            let mut labels = vec![0.01; 10];
            labels[label as usize] += 0.99;
            Image {
                label: labels,
                datapoints: image
                    .iter()
                    // important to normalize the values because of sigmoid (between 0 and 1)
                    .map(|f| (((*f as f64) / 255.0) * 0.99) + 0.01)
                    .collect(),
            }
        })
        .collect::<Vec<Image>>()
}
